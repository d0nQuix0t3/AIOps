---
version: '3.3'
services:


  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_STACK_VERSION}
    hostname: elasticsearch
    container_name: elasticsearch
    environment:
      - "http.host=0.0.0.0"
      - "transport.host=127.0.0.1"
      - "xpack.monitoring.collection.enabled=true"
    ports:
      - "127.0.0.1:9200:9200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cat/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - stack


  kibana:
    image: docker.elastic.co/kibana/kibana:${ELASTIC_STACK_VERSION}
    hostname: kibana
    container_name: kibana
    ports:
      - "127.0.0.1:5601:5601"
    networks:
      - stack
    depends_on:
      - elasticsearch


  logstash:
    image: docker.elastic.co/logstash/logstash:${ELASTIC_STACK_VERSION}
    hostname: logstash
    container_name: logstash
    environment:
      - "xpack.monitoring.enabled=true"
    ports:
      - "127.0.0.1:4560:4560"
      - "127.0.0.1:5044:5044"
    volumes:
      # Provide a pipeline configuration for Logstash with a bind-mounted file
      - ./elk/filebeat-logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    networks:
      - stack
    depends_on:
      - elasticsearch


  # Filebeat sending data to Logstash
  filebeat_for_logstash:
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION}
    hostname: filebeat_for_logstash
    container_name: filebeat_for_logstash
    volumes:
      # Bind-mount the logs/ directory, so Filebeat can read its files
      - "./elk/logs-docker/:/mnt/logs/:ro"
      # Bind-mount a custom configuration file
      - "./elk/filebeat-logstash/filebeat-logstash.yml:/usr/share/filebeat/filebeat.yml:ro"
      # Bind-mount the config directory so it can be dynamically loaded
      - "./elk/filebeat-logstash/config/:/usr/share/filebeat/config/:ro"
      # Bind-mount the registry file to avoid data duplication between restarts
      - "./elk/filebeat-logstash/registry/:/usr/share/filebeat/data/"
    command: filebeat -e
    restart: on-failure
    networks:
      - stack
    depends_on:
      - elasticsearch
      - logstash


  # Filebeat receiving syslog data and sending it to Elasticsearch
  filebeat_syslog:
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION}
    hostname: filebeat_syslog
    container_name: filebeat_syslog
    command: filebeat -e
    restart: on-failure
    volumes:
      # Bind-mount a custom configuration file
      - "./elk/filebeat-syslog/filebeat-syslog.yml:/usr/share/filebeat/filebeat.yml:ro"
      # Bind-mount the config directory so it can be dynamically loaded
      - "./elk/filebeat-syslog/config/:/usr/share/filebeat/config/:ro"
      # Bind-mount the registry file to avoid data duplication between restarts
      - "./elk/filebeat-syslog/registry/:/usr/share/filebeat/data/"
    networks:
      - stack
    depends_on:
      - elasticsearch


  # Filebeat sending data to Elasticsearch
  filebeat_for_elasticsearch:
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION}
    hostname: filebeat_for_elasticsearch
    container_name: filebeat_for_elasticsearch
    volumes:
      # Bind-mount the logs/ directory, so Filebeat can read its files
      - "./elk/logs-docker/:/mnt/logs/:ro"
      # Bind-mount a custom configuration file
      - "./elk/filebeat-elasticsearch/filebeat-elasticsearch.yml:/usr/share/filebeat/filebeat.yml:ro"
      # Bind-mount the config directory so it can be dynamically loaded
      - "./elk/filebeat-elasticsearch/config/:/usr/share/filebeat/config/:ro"
      # Bind-mount the registry file to avoid data duplication between restarts
      - "./elk/filebeat-elasticsearch/registry/:/usr/share/filebeat/data/"
    command: filebeat -e
    restart: on-failure
    networks:
      - stack
    depends_on:
      - elasticsearch
      - kibana


  # Filebeat collecting from a Docker container and sending to Elasticsearch
  filebeat_docker_for_elasticsearch:
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION}
    hostname: filebeat_docker_for_elasticsearch
    container_name: filebeat_docker_for_elasticsearch
    user: root #To read the docker socket
    volumes:
      # Bind-mount the Docker log directory from the Java container, so Filebeat can read its files
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      # Bind-mount a custom configuration file
      - "./elk/filebeat-docker/filebeat-docker.yml:/usr/share/filebeat/filebeat.yml:ro"
      # Bind-mount the registry file to avoid data duplication between restarts
      - "./elk/filebeat-docker/registry/:/usr/share/filebeat/data/"
      # Bind-mount the Filebeat log file (not going to system out to avoid a logging loop)
      - "./elk/filebeat-docker/logs/:/usr/share/filebeat/logs/"
      # Bind-mount the Docker daemon to enable add_docker_metadata from within the container
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    command: filebeat
    restart: on-failure
    networks:
      - stack
    depends_on:
      - elasticsearch
      - kibana


  # Metricbeat to optionally collect metrics from the entire setup; not required for logging itself
  metricbeat:
    hostname: metricbeat
    container_name: metricbeat
    user: root #To read the docker socket
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_STACK_VERSION}
    volumes:
      # Bind-mount a custom configuration file
      - "./elk/metricbeat/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      # Bind-mount the config directory so it can be dynamically loaded
      - "./elk/metricbeat/config/:/usr/share/metricbeat/config/:ro"
      # Monitor the Docker host rather than the Metricbeat container; these are used by the system module
      - "/proc:/hostfs/proc:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/:/hostfs:ro"
      # Bind-mount the Docker daemon to enable add_docker_metadata from within the container
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    command: metricbeat -e
    restart: on-failure
    networks:
      - stack
    depends_on:
      - elasticsearch
      - kibana


  # Metricbeat to optionally collect metrics from the entire setup; not required for logging itself
  heartbeat:
    hostname: heartbeat
    container_name: heartbeat
    user: root #To read the docker socket
    image: docker.elastic.co/beats/heartbeat:${ELASTIC_STACK_VERSION}
    volumes:
      # Bind-mount a custom configuration file
      - "./elk/heartbeat-system/heartbeat.yml:/usr/share/heartbeat/heartbeat.yml:ro"
      # Bind-mount the Docker daemon to enable add_docker_metadata from within the container
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    command: heartbeat -e
    restart: on-failure
    networks:
      - stack
    depends_on:
      - elasticsearch
      - kibana
      - logstash


  #Short lived container to configure the stack once Kibana and Elasticsearch are available
  configure_stack:
    image: docker.elastic.co/beats/filebeat:${ELASTIC_STACK_VERSION}
    hostname: configure_stack
    container_name: configure_stack
    volumes:
      - "./elk/config-elk/setup.sh:/usr/local/bin/setup.sh:ro"
      - "./elk/config-elk/setup_ingest-pipeline_parse-java.json:/usr/local/bin/setup_ingest-pipeline_parse-java.json:ro"
    command: /usr/local/bin/setup.sh
    networks:
      - stack
    depends_on:
      - elasticsearch
      - kibana

  # The syslog app sending messages continuously
  syslog_sender:
    image: syslog-sender:1.0.0
    hostname: syslog_sender
    container_name: syslog_sender
    build:
      dockerfile: $PWD/elk/custom-logger/custom_logger.dockerfile
      context: $PWD/elk/custom-logger/
    networks:
      - stack
    depends_on:
      - elasticsearch
      - filebeat_syslog


  apmserver:
    image: docker.elastic.co/apm/apm-server:${ELASTIC_STACK_VERSION}
    hostname: apmserver
    container_name: apmserver
    command: --strict.perms=false
    ports:
      - 8200:8200
      - 8201:8200
    environment:
      - apm-server.host=0.0.0.0
      - setup.kibana.host=kibana:5601
      - output.elasticsearch.hosts=["elasticsearch:9200"]
    depends_on:
      - elasticsearch
      - kibana
    # volumes:
    #   - ${PWD}/configs/apm-server.yml:/usr/share/apm-server/apm-server.yml
    networks:
        - stack

  apm-flask:
    hostname: apm-flask
    container_name: apm-flask
    build:
      dockerfile: $PWD/apps/apm-flask/apm-flask.dockerfile
      context: $PWD
    volumes:
      - ./apps/apm-flask:/code
    ports:
      - 5555:5555
    networks:
        - stack

  apm-dash:
    hostname: apm-dash
    container_name: apm-dash
    build:
      dockerfile: $PWD/apps/apm-dash/apm-dash.dockerfile
      context: $PWD
    volumes:
      - ./apps/apm-dash:/code
    ports:
      - 5556:5556
    networks:
        - stack


  #Packetbeat container
  packetbeat:
    container_name: packetbeat
    hostname: packetbeat
    image: "docker.elastic.co/beats/packetbeat:${ELASTIC_STACK_VERSION}"
    volumes:
      - ./elk/packetbeat-network/packetbeat.yml:/usr/share/packetbeat/packetbeat.yml
    # Packetbeat needs some elevated privileges to capture network traffic.
    # We'll grant them with POSIX capabilities.
    cap_add: ['NET_RAW', 'NET_ADMIN']
    # Use "host mode" networking to allow Packetbeat to capture traffic from
    # the real network interface on the host, rather than being isolated to the
    # container's virtual interface.
    network_mode: host
    command: packetbeat -e -E output.elasticsearch.hosts='["localhost:9200"]' -strict.perms=false
    restart: on-failure
    depends_on:
      - elasticsearch
      - kibana


  ml-sandbox:
    hostname: ml-sandbox
    container_name: ml-sandbox
    image: jupyter/datascience-notebook
    volumes:
      - $PWD/machine-learning/ml-sandbox:/home/jovyan/notebooks
    ports:
      - 8888:8888
    networks:
        - stack


networks:
  stack: {}
